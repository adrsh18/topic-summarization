{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded  100001  tweets\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "f = open('christmas-en-index-ready.txt', 'r')\n",
    "data = json.loads(f.read())\n",
    "f.close()\n",
    "print \"Loaded \", len(data), \" tweets\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import re\n",
    "import gensim\n",
    "from time import time\n",
    "from gensim import corpora, models, similarities\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class TweetTopicExtractor:\n",
    "    def __init__(self, data):\n",
    "        self.raw_data = data\n",
    "        self.documents = None\n",
    "        self.document_corpus = None\n",
    "        self.lda_model = None\n",
    "        self.doc2vec_model = None\n",
    "        self.gensim_dict = None\n",
    "    \n",
    "    def __cleanTokenize(self):\n",
    "        tweet_tokenizer = TweetTokenizer()\n",
    "        stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "        for tweet in self.raw_data:\n",
    "            text_arr = tweet_tokenizer.tokenize(tweet[\"tweet_text\"])\n",
    "            text_arr = [word for word in text_arr if word not in stopwords and re.search('[a-zA-Z]', word)]\n",
    "            tweet[\"tweet_text\"] = text_arr\n",
    "    \n",
    "    def __prepareDocuments(self):\n",
    "        documents = []\n",
    "        corp = []\n",
    "        LabeledSentence = gensim.models.doc2vec.LabeledSentence\n",
    "        for tweet in self.raw_data:\n",
    "            documents.append(LabeledSentence(tweet[\"tweet_text\"], [tweet[\"tweet_id\"]]))\n",
    "            corp.append(tweet[\"tweet_text\"])\n",
    "        self.documents = documents\n",
    "        self.document_corpus = corp\n",
    "    \n",
    "    def __getBagOfWords(self):\n",
    "        self.gensim_dict = corpora.Dictionary(self.document_corpus)\n",
    "        self.gensim_dict.filter_extremes(no_below=1, no_above=0.8)\n",
    "        return [self.gensim_dict.doc2bow(text) for text in self.document_corpus]\n",
    "    \n",
    "    def preprocess(self):\n",
    "        t_pp = time()\n",
    "        self.__cleanTokenize()\n",
    "        self.__prepareDocuments()\n",
    "        print \"Cleaned and loaded \", len(self.documents), \" documents (tweets) in \", round(time()-t_pp,2),\" seconds\"\n",
    "    \n",
    "    def buildLda(self, num_topics=4, num_passes=10):\n",
    "        t_lda = time()\n",
    "        bow_corpus = self.__getBagOfWords()\n",
    "        self.lda_model = models.LdaModel(bow_corpus, num_topics=num_topics, id2word=self.gensim_dict, update_every=5, chunksize=100010, passes=num_passes)\n",
    "        print \"Built LDA in \", round(time()-t_lda,2),\" seconds\"\n",
    "    \n",
    "    def printLdaSummary(self):\n",
    "        print \"\"\n",
    "        print \"Topics: Words that define the topic + probability with which word contributes to topic\"\n",
    "        print self.lda_model.show_topics()\n",
    "        \n",
    "        print \"\"\n",
    "        print \"Topics: Just words that define the topic\"\n",
    "        topics_matrix = self.lda_model.show_topics(formatted=False, num_words=20)\n",
    "        topics_matrix = np.array(topics_matrix)\n",
    "\n",
    "        topic_words = topics_matrix[:,:,1]\n",
    "        for i in topic_words:\n",
    "            print [str(word) for word in i]\n",
    "            print \"\"\n",
    "        \n",
    "        print \"\"\n",
    "        print \"thisObject.lda_model.xxxx() to explore further\"\n",
    "    \n",
    "    def buildDoc2Vec(self, alpha=0.03, min_alpha=0.03, num_passes=10):\n",
    "        t_dv = time()\n",
    "        self.doc2vec_model = models.Doc2Vec(alpha=alpha, min_alpha=min_alpha)\n",
    "        self.doc2vec_model.build_vocab(self.documents)\n",
    "        for i in range(num_passes):\n",
    "            self.doc2vec_model.train(self.documents)\n",
    "        print \"\"\n",
    "        print \"Built Doc2Vec in \",round(time()-t_dv,2), \" seconds\"\n",
    "    \n",
    "    def printDoc2VecSummary(self):\n",
    "        print \"\"\n",
    "        print \"Example: A tweet most similar to '#Xmas' can be found like this ->\"\n",
    "        print self.doc2vec_model.most_similar(\"#Xmas\")\n",
    "        print \"\"\n",
    "        print \"thisObject.doc2vec_model.xxxx() to explore further\"\n",
    "    \n",
    "    def saveModels(self, path_to_lda='cooper.lda', path_to_doc2vec='cooper.doc2vec'):\n",
    "        self.lda_model.save(path_to_lda)\n",
    "        self.doc2vec_model.save(path_to_doc2vec)\n",
    "        print \"Saved\"\n",
    "    \n",
    "    def loadModels(self, path_to_lda='cooper.lda', path_to_doc2vec='cooper.doc2vec'):\n",
    "        self.lda_model = LdaModel.load(path_to_lda, mmap='r')\n",
    "        self.doc2vec_model = Doc2Vec.load(path_to_doc2vec, mmap='r')\n",
    "        print \"Loaded\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned and loaded  100001  documents (tweets) in  10.31  seconds\n"
     ]
    }
   ],
   "source": [
    "tte = TweetTopicExtractor(data)\n",
    "tte.preprocess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Built Doc2Vec in  178.33  seconds\n",
      "\n",
      "Example: A tweet most similar to '#Xmas' can be found like this ->\n",
      "[(u'#Glamping', 0.2964997887611389), (u'#ShortStory', 0.28959375619888306), (u'#Workstations', 0.26019182801246643), (u'#Nuneaton', 0.2574554681777954), (u'#retaildesign', 0.25578734278678894), (u'#TRUMP2016', 0.25165659189224243), (u'#EJwtt', 0.2496497929096222), (u'Teens', 0.24932417273521423), (u'#GADGETS', 0.2442663013935089), (u'#planner', 0.23789329826831818)]\n",
      "\n",
      "thisObject.doc2vec_model.xxxx() to explore further\n"
     ]
    }
   ],
   "source": [
    "tte.buildDoc2Vec()\n",
    "tte.printDoc2VecSummary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built LDA in  1767.8  seconds\n",
      "\n",
      "Topics: Words that define the topic + probability with which word contributes to topic\n",
      "[(0, u'0.081*\"#Christmas\" + 0.011*\"Christmas\" + 0.009*\"The\" + 0.007*\"#christmas\" + 0.007*\"time\" + 0.006*\"#Win\" + 0.006*\"#giveaway\" + 0.005*\"year\" + 0.004*\"It\\'s\" + 0.004*\"new\"'), (1, u'0.051*\"#Christmas\" + 0.045*\"#christmas\" + 0.019*\"#christmascookies\" + 0.019*\"#christmascrush\" + 0.019*\"#christmasmatch3\" + 0.019*\"#santa\\'schimney\" + 0.019*\"#sweeper\" + 0.018*\"December\" + 0.011*\"1st\" + 0.010*\"Christmas\"'), (2, u'0.045*\"#Christmas\" + 0.042*\"#christmas\" + 0.031*\"Christmas\" + 0.009*\"like\" + 0.007*\"It\\'s\" + 0.007*\"look\" + 0.006*\"I\" + 0.006*\"Days\" + 0.006*\"lot\" + 0.005*\"beginning\"'), (3, u'0.057*\"#Christmas\" + 0.023*\"#christmas\" + 0.010*\"Christmas\" + 0.005*\"via\" + 0.005*\"The\" + 0.004*\"gift\" + 0.004*\"#gifts\" + 0.004*\"#gift\" + 0.004*\"#Xmas\" + 0.004*\"#Gifts\"')]\n",
      "\n",
      "Topics: Just words that define the topic\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-c27a5f606b38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtte\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuildLda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtte\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprintLdaSummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-d83060c924c6>\u001b[0m in \u001b[0;36mprintLdaSummary\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Topics: Just words that define the topic\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mtopics_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlda_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_topics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformatted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mtopics_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopics_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mtopic_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtopics_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence"
     ]
    }
   ],
   "source": [
    "tte.buildLda()\n",
    "tte.printLdaSummary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved\n"
     ]
    }
   ],
   "source": [
    "tte.saveModels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
